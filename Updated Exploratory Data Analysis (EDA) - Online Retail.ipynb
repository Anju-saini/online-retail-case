
Introduction
In this notebook, I will be exploring an online retail dataset in order to get insights from it.

import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
I. Exploratory Data Analysis
#load the dataset
retail_df = pd.read_excel("Online Retail.xlsx")
#shape of our dataset
print("The shape of our dataset is: ", retail_df.shape)
The shape of our dataset is:  (541909, 8)
#check the head of the dataset
retail_df.head(10)
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country
0	536365	85123A	WHITE HANGING HEART T-LIGHT HOLDER	6	2010-12-01 08:26:00	2.55	17850.0	United Kingdom
1	536365	71053	WHITE METAL LANTERN	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom
2	536365	84406B	CREAM CUPID HEARTS COAT HANGER	8	2010-12-01 08:26:00	2.75	17850.0	United Kingdom
3	536365	84029G	KNITTED UNION FLAG HOT WATER BOTTLE	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom
4	536365	84029E	RED WOOLLY HOTTIE WHITE HEART.	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom
5	536365	22752	SET 7 BABUSHKA NESTING BOXES	2	2010-12-01 08:26:00	7.65	17850.0	United Kingdom
6	536365	21730	GLASS STAR FROSTED T-LIGHT HOLDER	6	2010-12-01 08:26:00	4.25	17850.0	United Kingdom
7	536366	22633	HAND WARMER UNION JACK	6	2010-12-01 08:28:00	1.85	17850.0	United Kingdom
8	536366	22632	HAND WARMER RED POLKA DOT	6	2010-12-01 08:28:00	1.85	17850.0	United Kingdom
9	536367	84879	ASSORTED COLOUR BIRD ORNAMENT	32	2010-12-01 08:34:00	1.69	13047.0	United Kingdom
retail_df.tail(10)
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country
541899	581587	22726	ALARM CLOCK BAKELIKE GREEN	4	2011-12-09 12:50:00	3.75	12680.0	France
541900	581587	22730	ALARM CLOCK BAKELIKE IVORY	4	2011-12-09 12:50:00	3.75	12680.0	France
541901	581587	22367	CHILDRENS APRON SPACEBOY DESIGN	8	2011-12-09 12:50:00	1.95	12680.0	France
541902	581587	22629	SPACEBOY LUNCH BOX	12	2011-12-09 12:50:00	1.95	12680.0	France
541903	581587	23256	CHILDRENS CUTLERY SPACEBOY	4	2011-12-09 12:50:00	4.15	12680.0	France
541904	581587	22613	PACK OF 20 SPACEBOY NAPKINS	12	2011-12-09 12:50:00	0.85	12680.0	France
541905	581587	22899	CHILDREN'S APRON DOLLY GIRL	6	2011-12-09 12:50:00	2.10	12680.0	France
541906	581587	23254	CHILDRENS CUTLERY DOLLY GIRL	4	2011-12-09 12:50:00	4.15	12680.0	France
541907	581587	23255	CHILDRENS CUTLERY CIRCUS PARADE	4	2011-12-09 12:50:00	4.15	12680.0	France
541908	581587	22138	BAKING SET 9 PIECE RETROSPOT	3	2011-12-09 12:50:00	4.95	12680.0	France
Let's explore our dataset first by getting more information about rows and columns.

retail_df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 541909 entries, 0 to 541908
Data columns (total 8 columns):
InvoiceNo      541909 non-null object
StockCode      541909 non-null object
Description    540455 non-null object
Quantity       541909 non-null int64
InvoiceDate    541909 non-null datetime64[ns]
UnitPrice      541909 non-null float64
CustomerID     406829 non-null float64
Country        541909 non-null object
dtypes: datetime64[ns](1), float64(2), int64(1), object(4)
memory usage: 33.1+ MB
Our dataset is composed of 541909 rows and 8 columns. When going through the columns, we notice that we have some missing values in the CustomerID column, as it only has 406829 values. Also the column Description has missing values. So, that should be considered when applying exploration to our dataset.

#exploring the unique values of each attribute
print("Number of transactions: ", retail_df['InvoiceNo'].nunique())
print("Number of products: ",retail_df['StockCode'].nunique())
print("Number of customers:", retail_df['CustomerID'].nunique() )
print("Percentage of customers NA: ", round(retail_df['CustomerID'].isnull().sum() * 100 / len(retail_df),2),"%" )
print('Number of countries: ',retail_df['Country'].nunique())
Number of transactions:  25900
Number of products:  4070
Number of customers: 4372
Percentage of customers NA:  24.93 %
Number of countries:  38
Note: The number of NA customers is quite large and that would impact the results.

This dataframe contains 8 variables that correspond to:

InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.
StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.
Description: Product (item) name. Nominal.
Quantity: The quantities of each product (item) per transaction. Numeric.
InvoiceDate: Invoice Date and time. Numeric, the day and time when each transaction was generated.
UnitPrice: Unit price. Numeric, Product price per unit in sterling.
CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.
Country: Country name. Nominal, the name of the country where each customer resides.

Now, let's have an idea about the quantitative data (Quantity & UnitPrice).

retail_df.describe()
Quantity	UnitPrice	CustomerID
count	541909.000000	541909.000000	406829.000000
mean	9.552250	4.611114	15287.690570
std	218.081158	96.759853	1713.600303
min	-80995.000000	-11062.060000	12346.000000
25%	1.000000	1.250000	13953.000000
50%	3.000000	2.080000	15152.000000
75%	10.000000	4.130000	16791.000000
max	80995.000000	38970.000000	18287.000000
The first thing to notice is that we have some negative values in our dataset. Maybe, this could mean that these quantities (with corresponding UnitPrice values) was returned or cancelled.

I.1 Verify Assumption: Cancelled invoices
As mentioned in the description of the dataset, some InvoiceNo start with the letter "c" = cancelled. Let's see if our assumption is correct about the negative quantity: -80995.
We will look for the list of cancelled invoices and check if there is an invoice with that quantity.

#get cancelled transactions
cancelled_orders = retail_df[retail_df['InvoiceNo'].astype(str).str.contains('C')]
cancelled_orders.head()
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country
141	C536379	D	Discount	-1	2010-12-01 09:41:00	27.50	14527.0	United Kingdom
154	C536383	35004C	SET OF 3 COLOURED FLYING DUCKS	-1	2010-12-01 09:49:00	4.65	15311.0	United Kingdom
235	C536391	22556	PLASTERS IN TIN CIRCUS PARADE	-12	2010-12-01 10:24:00	1.65	17548.0	United Kingdom
236	C536391	21984	PACK OF 12 PINK PAISLEY TISSUES	-24	2010-12-01 10:24:00	0.29	17548.0	United Kingdom
237	C536391	21983	PACK OF 12 BLUE PAISLEY TISSUES	-24	2010-12-01 10:24:00	0.29	17548.0	United Kingdom
#search for transaction where quantity == -80995
cancelled_orders[cancelled_orders['Quantity']==-80995]
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country
540422	C581484	23843	PAPER CRAFT , LITTLE BIRDIE	-80995	2011-12-09 09:27:00	2.08	16446.0	United Kingdom
cancelled_orders[cancelled_orders['Quantity']>0]
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country
As we expected, negative values in the Quantity column, mean that it's a cancelled quantity because we didn't find any positive value for orders where InvoiceNo contains the prefix C.
How much cancelled orders do we have?

#check how many rows our dataframe of cancelled orders contain
print("We have ",len(cancelled_orders), " cancelled orders.")
#percentage of cancelled orders in total orders
total_orders = retail_df['InvoiceNo'].nunique()
cancelled_number = len(cancelled_orders)
print('Percentage of orders canceled: {}/{} ({:.2f}%) '.format(cancelled_number, total_orders, cancelled_number/total_orders*100))
We have  9288  cancelled orders.
Percentage of orders canceled: 9288/25900 (35.86%) 
We have a large percentage of cancelled orders of 35%. Studying these cancelled orders may help in preventing future cancellation. Let's first get an overview of the general customers purchase behavior and then dig deeper.

I.2 Explore Basket/Orders
I.2.a) What's the average number of orders per customer?
# get unique InvoiceNo number per customer
groupby_customers = pd.DataFrame(retail_df.groupby('CustomerID')['InvoiceNo'].nunique())
groupby_customers.head()
InvoiceNo
CustomerID	
12346.0	2
12347.0	7
12348.0	4
12349.0	1
12350.0	1
groupby_customers.describe()
InvoiceNo
count	4372.000000
mean	5.075480
std	9.338754
min	1.000000
25%	1.000000
50%	3.000000
75%	5.000000
max	248.000000
The average number of orders per customer is 5.

As we found in descriptive statistics that customers buy in average (mean) a quantity of 10. Are they from the same product? Let's examine how many products are purchased.

I.2.b) What's the average number of unique items per order?
groupby_invoice = pd.DataFrame(retail_df.groupby('InvoiceNo')['StockCode'].nunique())
groupby_invoice.columns=['productsNumber']
groupby_invoice.head()
productsNumber
InvoiceNo	
536365	7
536366	2
536367	12
536368	4
536369	1
groupby_invoice.describe()
productsNumber
count	25900.000000
mean	20.510618
std	42.500488
min	1.000000
25%	2.000000
50%	10.000000
75%	23.000000
max	1110.000000
retail_df.groupby(['InvoiceNo','CustomerID'])['StockCode'].nunique().describe()
count    22190.000000
mean        17.876566
std         22.872614
min          1.000000
25%          3.000000
50%         12.000000
75%         24.000000
max        541.000000
Name: StockCode, dtype: float64
temp_df =retail_df.groupby(['InvoiceNo','CustomerID'],as_index=False)['InvoiceDate'].count()
transaction_df = temp_df.rename(columns = {'InvoiceDate':'Number of products'})
transaction_df.head()
InvoiceNo	CustomerID	Number of products
0	536365	17850.0	7
1	536366	17850.0	2
2	536367	13047.0	12
3	536368	13047.0	4
4	536369	13047.0	1
transaction_df.describe()
CustomerID	Number of products
count	22190.000000	22190.000000
mean	15238.498738	18.333889
std	1733.149624	23.892111
min	12346.000000	1.000000
25%	13755.000000	3.000000
50%	15136.000000	12.000000
75%	16746.000000	24.000000
max	18287.000000	542.000000
As images speak more, let's see what the distribution of productsNumber tells us.

#Visualize the variable productsNumber distribution
fig, ax = plt.subplots()
fig.set_size_inches(11.7, 10)
sns.distplot(groupby_invoice['productsNumber'],ax=ax)
plt.show()
/home/sarahm/anaconda3/envs/py34/lib/python3.4/site-packages/statsmodels/nonparametric/kdetools.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y = X[:m/2+1] + np.r_[0,X[m/2+1:],0]*1j

We have a skewed distribution of products. Most people buy less than 25 items.

Customers by country
retail_df['total_cost'] = retail_df['Quantity'] * retail_df['UnitPrice']
retail_df.head()
InvoiceNo	StockCode	Description	Quantity	InvoiceDate	UnitPrice	CustomerID	Country	total_cost
0	536365	85123A	WHITE HANGING HEART T-LIGHT HOLDER	6	2010-12-01 08:26:00	2.55	17850.0	United Kingdom	15.30
1	536365	71053	WHITE METAL LANTERN	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom	20.34
2	536365	84406B	CREAM CUPID HEARTS COAT HANGER	8	2010-12-01 08:26:00	2.75	17850.0	United Kingdom	22.00
3	536365	84029G	KNITTED UNION FLAG HOT WATER BOTTLE	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom	20.34
4	536365	84029E	RED WOOLLY HOTTIE WHITE HEART.	6	2010-12-01 08:26:00	3.39	17850.0	United Kingdom	20.34
What's the total revenue per country?

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
fig, ax = plt.subplots()
fig.set_size_inches(13, 11.5)
ax=sns.barplot(x='Country', y='total_cost',data=retail_df,estimator=max,ax=ax)
ax.set_xticklabels(ax.get_xticklabels(), rotation=47, ha="right")
plt.show()

retail_df.groupby('Country').sum().sort_values(by='total_cost', ascending=False)
Quantity	UnitPrice	CustomerID	total_cost
Country				
United Kingdom	4263829	2.245715e+06	5.626433e+09	8.187806e+06
Netherlands	200128	6.492550e+03	3.419054e+07	2.846615e+05
EIRE	142637	4.844719e+04	1.103917e+08	2.632768e+05
Germany	117448	3.766600e+04	1.200751e+08	2.216982e+05
France	110480	4.303199e+04	1.076489e+08	1.974039e+05
Australia	83653	4.054750e+03	1.569300e+07	1.370773e+05
Switzerland	30325	6.813690e+03	2.377592e+07	5.638535e+04
Spain	26824	1.263345e+04	3.268929e+07	5.477458e+04
Belgium	23152	7.540130e+03	2.571829e+07	4.091096e+04
Sweden	35637	1.806830e+03	6.790083e+06	3.659591e+04
Japan	25218	8.148600e+02	4.567292e+06	3.534062e+04
Norway	19247	6.529060e+03	1.350765e+07	3.516346e+04
Portugal	16180	1.303754e+04	1.886480e+07	2.936702e+04
Finland	10666	3.786850e+03	8.699324e+06	2.232674e+04
Channel Islands	9479	3.738550e+03	1.128522e+07	2.008629e+04
Denmark	8188	1.266950e+03	4.876734e+06	1.876814e+04
Italy	7999	3.879390e+03	1.015666e+07	1.689051e+04
Cyprus	6317	3.920070e+03	7.715880e+06	1.294629e+04
Austria	4827	1.701520e+03	5.021102e+06	1.015432e+04
Hong Kong	4769	1.224150e+04	NaN	1.011704e+04
Singapore	5234	2.510889e+04	2.918376e+06	9.120390e+03
Israel	4353	1.079040e+03	3.164467e+06	7.907820e+03
Poland	3653	1.422270e+03	4.341972e+06	7.213140e+03
Unspecified	3300	1.204010e+03	3.348046e+06	4.749790e+03
Greece	1556	7.132900e+02	2.008584e+06	4.710520e+03
Iceland	2458	4.812100e+02	2.247154e+06	4.310000e+03
Canada	2763	9.105800e+02	2.615483e+06	3.666380e+03
Malta	944	6.660100e+02	2.158496e+06	2.505470e+03
United Arab Emirates	982	2.298900e+02	1.018952e+06	1.902280e+03
USA	1034	6.449800e+02	3.672086e+06	1.730920e+03
Lebanon	386	2.424400e+02	5.743800e+05	1.693880e+03
Lithuania	652	9.944000e+01	5.366200e+05	1.661060e+03
European Community	497	2.940500e+02	9.215880e+05	1.291750e+03
Brazil	356	1.426000e+02	4.086080e+05	1.143600e+03
RSA	352	2.481000e+02	7.218680e+05	1.002310e+03
Czech Republic	592	8.815000e+01	3.834300e+05	7.077200e+02
Bahrain	260	8.657000e+01	2.100270e+05	5.484000e+02
Saudi Arabia	75	2.411000e+01	1.256500e+05	1.311700e+02
As we can see, the largest market is the one located in UK.

retail_df[retail_df['Country']=='United Kingdom']['CustomerID'].nunique()
3950
So, we can conclude not only most sales revenues are achieved in the UK, but also most customers are located there too. We can explore this to find more about what products the customers buy together and what possible future opportunities in the UK Market.

retail_uk = retail_df[retail_df['Country']=='United Kingdom']
retail_uk.describe()
Quantity	UnitPrice	CustomerID	total_cost
count	495478.000000	495478.000000	361878.000000	495478.000000
mean	8.605486	4.532422	15547.871368	16.525065
std	227.588756	99.315438	1594.402590	394.839116
min	-80995.000000	-11062.060000	12346.000000	-168469.600000
25%	1.000000	1.250000	14194.000000	3.290000
50%	3.000000	2.100000	15514.000000	8.290000
75%	10.000000	4.130000	16931.000000	16.630000
max	80995.000000	38970.000000	18287.000000	168469.600000
print("Number of transactions: ", retail_uk['InvoiceNo'].nunique())
print("Number of products bought: ",retail_uk['StockCode'].nunique())
print("Number of customers:", retail_uk['CustomerID'].nunique() )
print("Percentage of customers NA: ", round(retail_uk['CustomerID'].isnull().sum() * 100 / len(retail_uk),2),"%" )
print('Number of countries: ',retail_uk['Country'].nunique())
Number of transactions:  23494
Number of products bought:  4065
Number of customers: 3950
Percentage of customers NA:  26.96 %
Number of countries:  1
Explore quantity
What are the products that are most bought in UK?

groupedProduct = retail_uk.groupby('StockCode',as_index= False)['Quantity'].sum().sort_values(by='Quantity', ascending=False)
groupedProduct.head(10)
#check how to show product description instead of StockCode
StockCode	Quantity
1068	22197	52928
2620	84077	48326
3655	85099B	43167
3666	85123A	36706
2733	84879	33519
1451	22616	25307
375	21212	24702
1049	22178	23242
39	17003	22801
887	21977	20288
invoice_quantity= retail_uk.groupby('InvoiceNo', as_index=False)['Quantity'].sum().sort_values(by='Quantity', ascending=False)
invoice_quantity.head()
InvoiceNo	Quantity
20090	581483	80995
2136	541431	74215
17136	574941	14149
17765	576365	13956
13770	567423	12572
It's important to know more about these most bought products. Is there any products that when one of them is bought, the other is bought too? To get an answer we will do "Market Basket Analysis" to find which products tend to be purchased together and which are most amenable to promotion.
